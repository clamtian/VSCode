# 1. 互斥与同步

同步与互斥是两种不同的概念：

* 同步就好比：「操作 A 应在操作 B 之前执行」，「操作 C 必须在操作 A 和操作 B 都完成之后才能执行」等；
* 互斥就好比：「操作 A 和操作 B 不能在同一时刻执行」。

## 1.1 互斥

由于多线程执行操作共享变量的这段代码可能会导致竞争状态，因此我们将此段代码称为临界区（critical section），它是访问共享资源的代码片段，一定不能给多线程同时执行。

我们希望这段代码是互斥（mutualexclusion）的，也就说保证一个线程在临界区执行时，其他线程应该被阻止进入临界区，说白了，就是这段代码执行过程中，最多只能出现一个线程。

## 1.2 同步

我们都知道在多线程里，每个线程并不一定是顺序执行的，它们基本是以各自独立的、不可预知的速度向前推进，但有时候我们又希望多个线程能密切合作，以实现一个共同的任务。

例子，线程 1 是负责读入数据的，而线程 2 是负责处理数据的，这两个线程是相互合作、相互依赖的。线程 2 在没有收到线程 1 的唤醒通知时，就会一直阻塞等待，当线程 1 读完数据需要把数据传给线程 2 时，线程 1 会唤醒线程 2，并把数据交给线程 2 处理。

所谓同步，就是并发进程/线程在一些关键点上可能需要互相等待与互通消息，这种相互制约的等待与互通信息称为进程/线程同步。

# 2. 互斥和同步的实现

## 2.1 锁

使用加锁操作和解锁操作可以解决并发线程/进程的互斥问题。

任何想进入临界区的线程，必须先执行加锁操作。若加锁操作顺利通过，则线程可进入临界区；在完成对临界资源的访问后再执行解锁操作，以释放该临界资源。

## 2.1.1 忙等待锁

在说明「忙等待锁」的实现之前，先介绍现代 CPU 体系结构提供的特殊原子操作指令 —— **测试和置位（Test-and-Set）指令**。

如果用 C 代码表示 TAS 指令，形式如下：

```javascript
// 伪代码  实际是由硬件支持 不可重入
int TestAndSet(int *old_ptr, int new) {
   int old = *old_ptr;
   *old_ptr = new;
   return old;
}
```
测试并设置指令做了下述事情:

* 把 old_ptr 更新为 new 的新值；
* 返回 old_ptr 的旧值；

当然，关键是这些代码是原子执行。因为既可以测试旧值，又可以设置新值，所以我们把这条指令叫作「测试并设置」。

那什么是原子操作呢？原子操作就是要么全部执行，要么都不执行，不能出现执行到一半的中间状态。

我们可以运用 TAS 指令来实现「忙等待锁」，代码如下：

```javascript
typedef struct lock_t {
   int flag;
} lock_t;

void init(lock_t *lock) {
   lock->flag = 0;
}

void lock(lock_t *lock) {
   while (TestAndSet(&lock->flag, 1) == 1);
}

void unlock(lock_t *lock) {
   lock->flag = 0;
}
```

我们来确保理解为什么这个锁能工作：

* 第一个场景是，首先假设一个线程在运行，调用 lock()，没有其他线程持有锁，所以 flag 是 0。当调用 TestAndSet(flag, 1) 方法，返回 0，线程会跳出 while 循环，获取锁。同时也会原子的设置 flag 为1，标志锁已经被持有。当线程离开临界区，调用 unlock() 将 flag 清理为 0。

* 第二种场景是，当某一个线程已经持有锁（即 flag 为1）。本线程调用 lock()，然后调用 TestAndSet(flag, 1)，这一次返回 1。只要另一个线程一直持有锁，TestAndSet() 会重复返回 1，本线程会一直忙等。当 flag 终于被改为 0，本线程会调用 TestAndSet()，返回 0 并且原子地设置为 1，从而获得锁，进入临界区。

很明显，当获取不到锁时，线程就会一直 while 循环，不做任何事情，所以就被称为「忙等待锁」，也被称为自旋锁（spin lock）。

这是最简单的一种锁，一直自旋，利用 CPU 周期，直到锁可用。在单处理器上，需要抢占式的调度器（即不断通过时钟中断一个线程，运行其他线程）。否则，自旋锁在单 CPU 上无法使用，因为一个自旋的线程永远不会放弃 CPU。

## 2.1.2 无等待锁

无等待锁顾明思议就是获取不到锁的时候，不用自旋。

既然不想自旋，那当没获取到锁的时候，就把当前线程放入到锁的等待队列，然后执行调度程序，把 CPU 让给其他线程执行。

```javascript
typedef struct lock_t {
   int flag;
   queue_t *q;  // 等待队列
} lock_t;

void init(lock_t *lock) {
   lock->flag = 0;
   queue_init(lock->q);
}

void lock(lock_t *lock) {
   while(TestAndSet(&lock->flag, 1) == 1) {
      /*
       * 保存现在运行线程 TCB（Thread Control Block）线程控制模块
       * 将现在运行的线程 TCB 插入到等待队列
       * 设置该线程为等待状态
       * 调度程序
       */
   }
}

void unlock(lock_t *lock) {
   if(lock->q != NULL) {
      /*
       * 移出等待队列的队头元素
       * 将该线程的 TCB 插入到就绪队列
       * 设置该线程为就绪状态
       */
   }
   lock->flag = 0;
}
```

## 2.2 信号量

信号量其实是一个整型的计数器，主要用于实现进程间的互斥与同步，而不是用于缓存进程间通信的数据。

信号量表示资源的数量，控制信号量的方式有两种原子操作：

* 一个是 P 操作，这个操作会把信号量减去 1，相减后如果信号量 < 0，则表明资源已被占用，进程需阻塞等待；相减后如果信号量 >= 0，则表明还有资源可使用，进程可正常继续执行。
* 另一个是 V 操作，这个操作会把信号量加上 1，相加后如果信号量 <= 0，则表明当前有阻塞中的进程，于是会将该进程唤醒运行；相加后如果信号量 > 0，则表明当前没有阻塞中的进程；
  
P 操作是用在进入共享资源之前，V 操作是用在离开共享资源之后，这两个操作是必须成对出现的。

信号量数据结构与 PV 操作的算法描述如下图：

```javascript
// 信号量数据结构

typedef struct sem_t {
   int sem;   // 资源个数
   queue_t *q;  // 等待队列
} sem_t;

// 初始化信号量
void init(sem_t *s, int sem) {
   s->sem = sem;
   queue_init(s->q);
}

// P操作
void P(sem_t *s) {
   s->sem--;
   if(s->sem < 0) {
      /*
       * 保留调用线程 CPU 现场
       * 将该线程的 TCB 插入到 s 的等待队列
       * 设置该线程为等待状态
       * 执行调度程序
       */
   }
}

// V操作
void V(sem_t *s) {
   s->sem++;
   if(s->sem <= 0) {
      /*
       * 移出 s 等待队列队首元素
       * 将该线程的 TCB 插入就绪队列
       * 设置该线程为就绪状态
      */
   }
}
```
### 2.2.1 进程之间的互斥

![互斥](image/3_15.png)

如果要使得两个进程互斥访问共享内存，我们可以初始化信号量为 1。

具体的过程如下：

* 进程 A 在访问共享内存前，先执行了 P 操作，由于信号量的初始值为 1，故在进程 A 执行 P 操作后信号量变为 0，表示共享资源可用，于是进程 A 就可以访问共享内存。
* 若此时，进程 B 也想访问共享内存，执行了 P 操作，结果信号量变为了 -1，这就意味着临界资源已被占用，因此进程 B 被阻塞。
* 直到进程 A 访问完共享内存，才会执行 V 操作，使得信号量恢复为 0，接着就会唤醒阻塞中的线程 B，使得进程 B 可以访问共享内存，最后完成共享内存的访问后，执行 V 操作，使信号量恢复到初始值 1。
  
可以发现，信号初始化为 1，就代表着是互斥信号量，它可以保证共享内存在任何时刻只有一个进程在访问，这就很好的保护了共享内存

### 2.2.2 进程之间的同步

![同步](image/3_16.png)

在多进程里，每个进程并不一定是顺序执行的，它们基本是以各自独立的、不可预知的速度向前推进，但有时候我们又希望多个进程能密切合作，以实现一个共同的任务。

例如，进程 A 是负责生产数据，而进程 B 是负责读取数据，这两个进程是相互合作、相互依赖的，进程 A 必须先生产了数据，进程 B 才能读取到数据，所以执行是有前后顺序的。

那么这时候，就可以用信号量来实现多进程同步的方式，我们可以初始化信号量为 0。

具体过程：

* 如果进程 B 比进程 A 先执行了，那么执行到 P 操作时，由于信号量初始值为 0，故信号量会变为 -1，表示进程 A 还没生产数据，于是进程 B 就阻塞等待；
* 接着，当进程 A 生产完数据后，执行了 V 操作，就会使得信号量变为 0，于是就会唤醒阻塞在 P 操作的进程 B；
* 最后，进程 B 被唤醒后，意味着进程 A 已经生产了数据，于是进程 B 就可以正常读取数据了。

可以发现，信号初始化为 0，就代表着是同步信号量，它可以保证进程 A 应在进程 B 之前执行。
















# 16. 互斥锁

也叫互斥量，互斥锁是⼀种简单的加锁的方法来控制对共享资源的访问，互斥锁只有两种状态,即加锁( lock )和解锁( unlock )

1. 在访问共享资源后临界区域前，对互斥锁进行加锁。
2. 在访问完成后释放互斥锁导上的锁。
3. 对互斥锁进行加锁后，任何其他试图再次对互斥锁加锁的线程将会被阻塞，直到锁被释放。

# 17. 死锁（DeadLock）

如果⼀个进程集合中的每⼀个进程都在等待只能由该进程集合中的其他进程才能引发的事件，那么，该进程集合就是死锁。

## 17.1 资源

可抢占资源：可以从拥有它的进程中抢占而不会产生任何副作用，存储器就是⼀类可抢占资源

不可抢占资源：是指在不引起相关计算失败的情况下，无法把它从占有它的进程处抢占过来

## 17.2 必要条件

1. 互斥：每个资源要么已经分配给⼀个进程，要么就是可用的
2. 占有和等待：已经得到了某个资源的进程可以再请求新的资源
3. 不可抢占：已经分配给⼀个进程的资源不能强制性地被抢占，它只能被占有它的进程显式地释放
4. 环路等待：死锁发生时，系统中⼀定有由两个或两个以上的进程组成的⼀条环路，该环路中的每个进程都在等待着下⼀个进程所占有的资源。

## 17.3 处理方法

### 17.3.1 鸵鸟算法

把头埋在沙子⾥，假装根本没发生问题。

因为解决死锁问题的代价很高，因此鸵鸟算法这种不采取任务措施的方案会获得更高的性能。当发生死锁时不会对用户造成多大影响，或发生死锁的概率很低，可以采用鸵鸟算法。

### 17.3.2 死锁检测

**每种类型⼀个资源的死锁检测**

通过检测有向图中是否存在环来实现，从⼀个节点出发进行深度优先搜索，对访问过的节点进行标记，如果访问了已经标记的节点，就表示有向图存在环，也就是检测到死锁发生

**每种类型多个资源的死锁检测**

每个进程最开始时都不被标记，执行过程有可能被标记。当算法结束时，任何没有被标记的进程都是死锁进程。

1. 寻找⼀个没有标记的进程Pi，它所请求的资源小于或等于A
2. 如果真找到这样⼀个进程，那么将C矩阵的第i行向量加到A中，标记该进程，并转回第1步
3. 如果没有这样的进程，那么算法终止

### 17.3.3 死锁恢复

**利用抢占恢复**

将进程挂起，强行取⾛资源给另⼀个进程使用，用完再放回

**利用回滚恢复**

复位到更早的状态，那时它还没有取得所需的资源

**通过杀死进程恢复**

杀掉环中的⼀个进程或多个，牺牲掉⼀个环外进程

### 17.3.4 死锁预防

**破坏互斥条件**

例如假脱机打印机技术允许若⼲个进程同时输出，唯⼀真正请求物理打印机的进程是打印机守护进程。

**破坏占有等待条件**

1. 规定所有进程在开始执行前请求所需要的全部资源。
2. 要求当⼀个进程请求资源时，先暂时释放其当前占用的所有资源，然后在尝试⼀次获得所需的全部资源。

**破坏不可抢占条件**

1. 保证每⼀个进程在任何时刻只能占用⼀个资源，如果请求另⼀个资源必须先释放第⼀个资源
2. 将所有的资源统⼀编号，进程可以在任何时刻提出资源请求，但是所有请求必须按照资源编号的顺序(升序)提出
   
**破坏环路等待**

### 17.3.5 死锁避免

**安全状态**

如果没有死锁发生，并且即使所有进程突然请求对资源的最大需求，也仍然存在某种调度次序能够使得每⼀个进程运行完毕，则称该状态是安全的。

**单个资源的银行家算法**

⼀个小城镇的银行家，他向⼀群客户分别承诺了⼀定的贷款额度，算法要做的是判断对请求的满足是否会进入不安全状态，如果是，就拒绝请求；否则予以分配。

**多个资源的银行家算法**

检查⼀个状态是否安全的算法

1. 查找右边的矩阵是否存在⼀行小于等于向量 A。如果不存在这样的行，那么系统将会发生死锁，状态是不安全的。
2. 假若找到这样⼀行，将该进程标记为终止，并将其已分配资源加到 A 中。
3. 重复以上两步，直到所有进程都标记为终止，则状态是安全的。
   
如果⼀个状态不是安全的，需要拒绝进入这个状态。

# 10. 不可重入、可重入函数

如果有⼀个函数不幸被设计成为这样：不同任务调用这个函数时可能修改其他任务调用这个函数的数据，从而导致不可预料的后果。

这样的函数是不安全的函数，也叫不可重入函数;

**不可重入函数**

1. 函数体内使用了静态的数据结构;
2. 函数体内调用了malloc() 或者 free() 函数(谨慎使用堆);
3. 函数体内调用了标准 I/O 函数;

**可重入函数**

1. 所谓可重入是指⼀个可以被多个任务调用的过程，任务在调用时不必担⼼数据是否会出错;
2. 在写函数时候尽量使用局部变量（例如寄存器、栈中的变量）;
3. 对于要使用的全局变量要加以保护（如采取关中断、信号量等互斥方法），这样构成的函数就⼀定是⼀个可重入的函数.

# 18. 读写锁

在对数据的读写操作中，更多的是读操作，写操作较少，例如对数据库数据的读写应用。为了满足当前能够允许多个读出，但只允许⼀个写入的需求，线程提供了读写锁来实现。

**读写锁的特点**
1、如果有其它线程读数据，则允许其它线程执行读操作，但不允许写操作
2、如果有其它线程写数据，则其它线程都不允许读、写操作

读写锁分为读锁和写锁，规则如下

1. 如果某线程申请了读锁，其它线程可以再申请读锁，但不能申请写锁。
2. 如果某线程申请了写锁，其它线程不能申请读锁，也不能申请写锁。

# 19. 条件变量

与互斥锁不同，条件变量是用来等待而不是用来上锁的，条件变量本身不是锁！

条件变量用来自动阻塞⼀个线程，直到某特殊情况发生为止。通常条件变量和互斥锁同时使用。

条件变量的两个动作：
1. 条件不满, 阻塞线程
2. 当条件满足, 通知阻塞的线程开始⼯作

**条件变量的优缺点**

相较于mutex而⾔，条件变量可以减少竞争。

如直接使用mutex，除了生产者、消费者之间要竞争互斥􁰁以外，消费者之间也需要竞争互斥量;

但如果汇聚（链表）中没有数据，消费者之间竞争互斥锁是无意义的。有了条件变量机制以后，只有生产者完成生产，才会引起消费者之间的竞争。提高了程序效率。

**条件变量流程分析**

场景: 你是个老板，招聘了三个员⼯，但是你不是有了活才去招聘员⼯，而是先把员⼯招来，没有活的时候员⼯需要在那⾥等着，⼀旦有了活，你要去通知他们，他们要去抢活⼲，⼲完了再等待，你再有活，再通知他们

# 20. 信号量

信号量⼴泛用于进程或线程间的同步和互斥，信号􁰁本质上是⼀个非负的整数计数器，它被用来控制对公共资源的访问。

编程时可根据操作信号􁰁值的结果判断是否对公共资源具有访问的权限，当信号量值大于 0时，则可以访问，否则将阻塞。

PV 原语是对信号量的操作，⼀次 P 操作使信号量减１，⼀次 V 操作使信号量加１。

# 21. 经典的IPC问题

## 21.1 哲学家进餐问题

下面是⼀种错误的解法，如果所有哲学家同时拿起左⼿边的筷子，那么所有哲学家都在等待其它哲学家吃完并释放自己⼿中的筷子，导致死锁。

为了防止死锁的发生，可以设置两个条件：

1. 必须同时拿起左右两根筷子
2. 只有在两个邻居都没有进餐的情况下才允许进餐

## 21.2 读者-写者问题

允许多个进程同时对数据进行读操作，但是不允许读和写以及写和写操作同时发生。

# 22. 文件系统

## 22.1 文件

文件是⼀种抽象机制，它提供了⼀种在磁上保存信息而且方便以后读取的方法。这种方法可以使用户不必了解存储信息的方法、位置和实际磁盘⼯作方式等有关细节

## 22.2 文件命名

win95、win98用的都是MS-DOS的文件系统，即FAT-16， win98扩展了FAT-16成为FAT-32。

较新版的操作系统NTFS,win8配备ReFS。微软优化FAT,叫作exFAT。prog.c，圆点后面的部分称为文件扩展名。

## 22.3 文件结构

**字节结构**

把文件看成字节序列为操作系统提供了最大的灵活度

**记录序列**

文件结构上的第⼀步改进，这种模型中，文件是具有固定长度记录的序列

**树**

文件在这种结构中由⼀棵记录树构成，每个记录不必具有相同的长度，记录的固定位置上有⼀个键字段。这棵树按“键”字段进行排序，从而可以对特定“键”进行快速查找。

## 22.4 文件类型

1. 普通文件
2. 目录
3. 字符特殊文件（UNIX）
4. 块特殊文件（UNIX）

## 22.5 文件访问

**顺序访问**

按顺序读取文件的全部字节，早期操作系统只有这种访问方式

**随机访问文件**

当用磁盘存储文件时，可以以任何次序读取其中字节或记录的文件。许多应用程序需要这种类型文件

## 22.6 文件属性

除了文件名和数据外，所有操作系统还会保存其他的文件相关信息，如创建⽇期、时间和大小等，这些附加的信息称为文件属性

## 22.7 文件操作

使用文件的目的是存储信息并方便以后检索。对于存储和检索，不同系统提供了不同的操作。

常⻅的文件操作（系统调用）:

1. create：创建不包含任何数据的文件
2. delete：当不再需要某个文件时，必须删除该文件以释放磁盘空间
3. open：在使用文件之前，必须先打开文件
4. close：访问结束后，不再需要文件属性和磁盘地址，这时应该关闭文件以释放内部表空间
5. read：在文件中读取数据
6. write：向文件写数据，写操作⼀般也是从文件当前位置开始
7. append：此调用是write的限制形式，他只能在文件末尾添加数据
8. seek：对于随机访问文件，要指定从何处开始获取数据，通常的方法是用seek系统调用把当前位置指针指向文件中特定的位置。
9. get attributes：进程运行常需要读取文件属性
10. set attributes：某些属性是可由用户设置的，甚至在文件创建之后
11. rename：用户尝尝要改变已有的名字，rename系统调用用于这⼀目的

## 22.8 目录

文件系统通常提供目录或文件夹用于记录文件的位置，在很多操作系统中目录本身也是文件

1. ⼀级目录系统：在⼀个目录中包含所有文件，这有时称为根目录
2. 层级目录系统：当用户有着数以千计的文件，为了寻找方便。需要层次结构（即⼀个目录树）
3. 路径名
   
   **绝对路径名**：它由从根目录到文件的路径组成。

   Windows ： \usr\ast\maibox

   UNIX ： /usr/ast/mailbox

   路径名的第⼀个字符是分隔符，则这个路径是绝对路径

   **相对路径名**：它常和⼯作目录(working directory)(也和当前目录(acurrent directory))⼀起使用

   **特殊目录项**：

   . dot ：指当前目录
   
   .. dotdot 指其父目录

4. 目录操作
   
```javascript
create # 创建目录
delete # 删除目录
opendir # 目录内容可被读取
closedir # 读目录结束
readdir # 返回打开目录下一个目录项
rename # 改变目录名
link # 链接技术允许在多个目录中出现同一个文件
unlink # 删除目录项
```

# 23. 文件系统的实现

文件存储实现的关键问题是记录各个文件分别用到哪些磁盘块。不同的操作系统用到不同的方法

## 23.1 文件系统布局

文件系统存放在磁盘上。多数磁盘划分为⼀个或多个分区，每个分区中国有⼀个独立的文件系统。

磁盘0号扇区称为主引导记录(MBR)，用来引导计算机。在MBR结尾是分区表。该表给出每个分区的起始结束地址。

表中的⼀个分区被标记为活动区。在计算机被引导时，BIOS读入并执行MBR。MBR做的第⼀件事是确定活动分区，读入它的第⼀个块，称为引导块，并执行之。

引导块中的程序将装载该分区中的操作系统。

## 23.2 文件的实现

**连续分配**

最简单的分配是把每个文件作为⼀连串连续数据块存储在磁盘

优势：

1. 实现简单：记录每个文件用到磁盘块简化为只需记住两个数字即可：第⼀块的磁盘地址和文件的块数。给定了第⼀块编号，⼀个简单的加法就可以找到任何其他块的编号

2. 操作性能较好：因为单个操作中就能从磁盘上读出整个文件。只需⼀次寻找。

**链表分配**

为每个文件构造磁盘块链表。每⼀块的第⼀个字作为指向下⼀块的指针，块的其他部分存放数据。

优势：

1. 可以充分利用磁盘块，不会因为磁盘碎片浪费存储内存
2. 随机访问快。
   
缺点：

指针占用⼀些字节，每个磁盘块存储数据的字节数不再是2的整数次幂。怪异的大小降低了系统的运行效率，每个块前⼏个字节被指向下⼀个块的指针所占据，需要从两个磁盘中获取拼接信息，这就因复制而引发额外的开销。

**采用内存中的表进行链表分配**

取出每个磁盘块的指针字，把他放在内存的⼀个表中，解决链表分配的不足。内存中这样的表格称为文件分配表(File Allocation Table，FAT)

**i节点**

最后⼀个记录各文件分别包含哪些磁盘块的方法是给每个文件赋予⼀个称为i节点的数据结构，其中列出了文件属性和文件的磁盘地址。

## 23.3 目录的实现

在读文件之前，必须先打开文件。打开文件时，操作系统利用用户给出的路径名找到相应的目录项。

简单目录：包含固定大小的目录，在目录项中有磁盘地址和属性

采用i节点的系统：把文件属性存放在i节点中而不是目录项中。这种情形下，目录项会更短。

## 23.4 共享文件

当⼏个用户同在⼀个项目⾥⼯作时，他们常常需要共享文件。

共享文件与目录的联系称为⼀个链接（link）。这样文件系统本身就是⼀个有向无环图（DAG），而不是⼀棵树。

## 23.5 ⽇志结构文件系统

CPU运行速度越来越快，磁盘容􁰁越来越大，价格越来越便宜（但磁盘速度并没有增快多少），同时内存容􁰁也以指数形式增长。

而没有得到快速发展的参数是磁道的寻道时间。这些成为了文件系统性能的瓶颈，为了解决这⼀问题设计了全新的文件系统即⽇志结构文件系统（LFS）。

虽然是⼀个很吸引⼈的想法，由于它们和文件系统不匹配，该文件系统并没有被⼴泛应用。

## 23.6 ⽇志文件系统

基本的想法是保存⼀个用于记录系统下⼀步将要做什么的⽇志。

这样当系统在完成他们即将完成的任务前崩溃时，􁯿新启动后，可以通过查看⽇志，获取崩溃前计划完成的任务，并完成它们。

这样的文件⽇志系统，并已经被实际应用。微软的NTFS、Linux的 ext3和ReiserFS文件系统都使用⽇志。

## 23.7 虚拟文件系统

将多个文件系统整合到⼀个统⼀的结构中。

⼀个Linux系统可以用ext2作为根文件系统，ext3分区装载在/usr下，另⼀块采用ReiserFS文件系统的硬盘装载在/home下，以及⼀个ISO 9660的CD-ROM临时装载在/mnt下。从用户的观点来看，只有⼀个文件系统层级。

它们事实上是多种文件系统，对于用户和进程是不可⻅的。绝大多数Unix操作系统都在使用虚拟文件系统（Virtual File System, VFS）

# 24. 文件系统的管理和优化

## 24.1 磁盘空间管理

⼏乎所有文件系统都把文件分割成固定大小的块来存储，各块之间不⼀定相邻

1、块大小

从历史的观点上来说，文件系统将大小设在1~4KB之间，但现在随着磁盘超过了1TB，还是将块的大小提升到64KB并且接受浪费的磁盘孔空间，这样也许更好。磁盘空间⼏乎不再会短缺。

2、记录空闲块

**磁盘块链表**

链表的每个块中包含尽可能多的空闲磁盘块号。

通常情况下，采用空闲块存放空闲表，这样不会影响存储器

**位图**

在位图中，空闲块用1表示，已分配块用0表示。

**磁盘配额**

为防止⼈们贪⼼而占有太多的磁盘空间，用户操作系统常常提供⼀种强制性磁盘配额机制。

其思想是系统管理员分给每个用户拥有文件和块的最大数􁰁，操作系统确保每个用户不超过分给他们的配额。（配额表、打开文件表）

## 24.2 文件系统备份

做磁盘备份主要是处理好两个潜在问题中的⼀个

1. 从意外的灾难中恢复
2. 从错误的操作中恢复

## 24.3 文件系统的⼀致性

很多文件系统读取磁盘块，进行修改后，再写回磁盘。

如果在修改过的磁盘块全部写回之前系统崩溃，则文件系统有可能处于不⼀致状态。

如果⼀些未被写回的块是i节点块、目录块或者是包含有空闲表的块时，这个问题尤为严重

## 24.4 文件系统性能

1、高速缓存

减少磁盘访问次数技术是块高速缓存（block cache）或者缓冲区高速缓存（buffer cache）。

本书中，高速缓存指的是⼀系列的块，它们在逻辑上属于磁盘，但实际上基于性能的考虑被保存在内存中。

2、块提取读

在需要用到块之前，试图提前将其写入高速缓存，从而提高命中率。

块提前读策略只适用于实际顺序读取的文件。对随机访问文件，提前读丝毫不起作用。

3、减少磁盘臂运动

把可能顺序访问的块放⼀起，当然最好是同⼀柱面上，从而减少磁盘臂的移动次数。

## 24.5 磁盘碎片整理

移动文件使它们相邻，并把所有的空闲空间放在⼀个或多个大的连续区域内。












